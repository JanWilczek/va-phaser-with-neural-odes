{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath = './diodeclip-input.wav'\n",
    "target_filepath = './diodeclip-target.wav'\n",
    "input_waveform, sample_rate = torchaudio.load(input_filepath)\n",
    "target_waveform, sample_rate = torchaudio.load(target_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_utils import play_audio, plot_waveform, print_stats, print_metadata, plot_specgram\n",
    "\n",
    "for filepath in [input_filepath, target_filepath]:\n",
    "    metadata = torchaudio.info(filepath)\n",
    "    print_metadata(metadata, src=filepath)\n",
    "    waveform, _ = torchaudio.load(filepath)\n",
    "    print_stats(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "assert input_waveform.shape == target_waveform.shape\n",
    "frames_count = input_waveform.shape[1]\n",
    "train_frames_count = int(0.8 * frames_count)\n",
    "train_input_waveform = input_waveform[0, :train_frames_count]\n",
    "# test_input_waveform = input_waveform[0, train_frames_count:]\n",
    "train_target_waveform = target_waveform[0, :train_frames_count]\n",
    "# test_target_waveform = target_waveform[0, train_frames_count:]\n",
    "# torchaudio.save('./test_target.wav', test_target_waveform.unsqueeze(0), sample_rate)\n",
    "# torchaudio.save('./test_input.wav', test_input_waveform.unsqueeze(0), sample_rate)\n",
    "test_input_waveform, _ = torchaudio.load('./test_input.wav')\n",
    "test_target_waveform, _ = torchaudio.load('./test_target.wav')\n",
    "test_input_waveform.squeeze_(0)\n",
    "test_target_waveform.squeeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTrajectoryNetworkFF(nn.Module):\n",
    "    def __init__(self, is_trained=False):\n",
    "        super().__init__()\n",
    "        self.densely_connected_layers = nn.Sequential(nn.Linear(2, 8, bias=False), nn.Tanh(), nn.Linear(8, 8, bias=False), nn.Tanh(), nn.Linear(8, 1, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_output = self.densely_connected_layers(x)\n",
    "        output = dense_output[..., 0] + x[..., 1]\n",
    "        return output.unsqueeze(-1)\n",
    "\n",
    "stn = StateTrajectoryNetworkFF(is_trained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTrajectoryNetwork(nn.Module):\n",
    "        def __init__(self, is_trained=False):\n",
    "        super().__init__()\n",
    "        self.densely_connected_layers = nn.Sequential(nn.Linear(2, 8, bias=False), nn.Tanh(), nn.Linear(8, 8, bias=False), nn.Tanh(), nn.Linear(8, 1, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.zeros_like(x)\n",
    "        \n",
    "        for i in range(x.shape[1]):\n",
    "            dense_output = self.densely_connected_layers(x)\n",
    "            output = dense_output[..., 0] + x[..., 1]\n",
    "        return output.unsqueeze(-1)\n",
    "\n",
    "    def initialize_state(self, batch_size, state_size):\n",
    "        self.state = torch.zeros((batch_size, state_size))\n",
    "\n",
    "# stn = StateTrajectoryNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device} for training.')\n",
    "\n",
    "stn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def normalized_mse_loss(output, target):\n",
    "    minimum_value = 1e-5 * torch.ones_like(target)\n",
    "    loss = torch.mean(torch.div((target - output) ** 2, torch.maximum(target ** 2, minimum_value)))\n",
    "    return loss\n",
    "\n",
    "optimizer = optim.Adam(stn.parameters(), lr=0.001)\n",
    "criterion = normalized_mse_loss\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stn)\n",
    "for param in stn.parameters():\n",
    "    print(type(param), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "sequence_length = 2048\n",
    "segments_count = train_frames_count // sequence_length\n",
    "input_batch = np.zeros((segments_count, sequence_length, 2))\n",
    "target_batch = np.zeros((segments_count, sequence_length, 1))\n",
    "for i in range(segments_count):\n",
    "    start_id = i * sequence_length\n",
    "    end_id = (i + 1) * sequence_length\n",
    "    input_batch[i, :, 0] = train_input_waveform[start_id:end_id]\n",
    "    input_batch[i, 1:, 1] = train_target_waveform[start_id:end_id-1]\n",
    "    target_batch[i, :, 0] = train_target_waveform[start_id:end_id]\n",
    "\n",
    "print(f'1 input minibatch shape: {input_batch.shape}')\n",
    "print(f'1 target minibatch shape: {target_batch.shape}')\n",
    "\n",
    "input_batch = torch.tensor(input_batch, dtype=torch.float, device=device)\n",
    "target_batch = torch.tensor(target_batch, dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "epochs = 200\n",
    "print_loss_every = 200\n",
    "segments_in_a_batch = 40\n",
    "batch_count = segments_count // segments_in_a_batch\n",
    "\n",
    "loss_history = torch.zeros((epochs,), device=device)\n",
    "gradient_norm_history = torch.zeros((epochs,), device=device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i in range(batch_count):\n",
    "        input_minibatch = input_batch[i*segments_in_a_batch:(i+1)*segments_in_a_batch, :, :]\n",
    "        target_minibatch = target_batch[i*segments_in_a_batch:(i+1)*segments_in_a_batch, :, :]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_minibatch = stn(input_minibatch)\n",
    "\n",
    "        loss = criterion(output_minibatch, target_minibatch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % print_loss_every == print_loss_every - 1:\n",
    "            print('[%d, %5d] loss: %.5f; Running loss: %.5f' % (epoch + 1, i + 1, loss.item(), running_loss/print_loss_every))\n",
    "            running_loss = 0.\n",
    "        \n",
    "    loss_history[epoch] = loss.item()\n",
    "    gradient = torch.cat([param.grad.flatten() for param in stn.parameters()])\n",
    "    gradient_norm_history[epoch] = torch.linalg.norm(gradient)\n",
    "\n",
    "print('Finished training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "plt.plot(loss_history.cpu())\r\n",
    "plt.xlabel('Epochs')\r\n",
    "plt.ylabel('Loss (Normalized MSE)')\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "plt.plot(gradient_norm_history.cpu())\r\n",
    "plt.xlabel('Epochs')\r\n",
    "plt.ylabel('Gradient L2 norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './diode_clipper_2x8tanhRNN.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(stn.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 1 batch, 1-element sequence, 2 variables (input and state, i.e., previous output)\n",
    "stn = stn.cpu()\n",
    "input_vector = torch.zeros((1, 1, 2), dtype=torch.float)\n",
    "output_vector = torch.zeros((1, 1, 1), dtype=torch.float)\n",
    "test_output = torch.zeros_like(test_input_waveform.to('cpu'))\n",
    "\n",
    "print('Processing test data...')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, sample in tqdm(enumerate(test_input_waveform), total=test_input_waveform.shape[0]):\n",
    "        input_vector[0, 0, 0] = sample\n",
    "        input_vector[0, 0, 1] = output_vector[0, 0, 0]\n",
    "\n",
    "        output_vector = stn(input_vector)\n",
    "\n",
    "        test_output[i] = output_vector[0, 0, 0]\n",
    "\n",
    "    test_loss = criterion(test_output, test_target_waveform)\n",
    "    print(f'Test loss: {test_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(test_output.unsqueeze(0))\n",
    "test_output = torch.clamp(test_output, -1., 1.)\n",
    "print_stats(test_output.unsqueeze(0))\n",
    "torchaudio.save('./test_output.wav', test_output.unsqueeze(0), sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python38264bitb968479eace84ce7bc6d1c4c913f31be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "8a6378035587bb97055001603ea9d85a2aa377cc6252a50ffca4355a71bc8b90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
