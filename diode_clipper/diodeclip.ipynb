{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitb968479eace84ce7bc6d1c4c913f31be",
   "display_name": "Python 3.8.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "8a6378035587bb97055001603ea9d85a2aa377cc6252a50ffca4355a71bc8b90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n",
      "1.8.1+cu111\n",
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath = './diodeclip-input.wav'\n",
    "target_filepath = './diodeclip-target.wav'\n",
    "input_waveform, sample_rate = torchaudio.load(input_filepath)\n",
    "target_waveform, sample_rate = torchaudio.load(target_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------\n",
      "Source: ./diodeclip-input.wav\n",
      "----------\n",
      " - sample_rate: 44100\n",
      " - num_channels: 1\n",
      " - num_frames: 21123903\n",
      " - bits_per_sample: 16\n",
      " - encoding: PCM_S\n",
      "\n",
      "Shape: (1, 21123903)\n",
      "Dtype: torch.float32\n",
      " - Max:      0.563\n",
      " - Min:     -0.566\n",
      " - Mean:    -0.000\n",
      " - Std Dev:  0.074\n",
      "\n",
      "tensor([[-3.0518e-05, -3.0518e-05, -3.0518e-05,  ..., -1.2207e-04,\n",
      "          9.1553e-05, -1.2207e-04]])\n",
      "\n",
      "----------\n",
      "Source: ./diodeclip-target.wav\n",
      "----------\n",
      " - sample_rate: 44100\n",
      " - num_channels: 1\n",
      " - num_frames: 21123903\n",
      " - bits_per_sample: 16\n",
      " - encoding: PCM_S\n",
      "\n",
      "Shape: (1, 21123903)\n",
      "Dtype: torch.float32\n",
      " - Max:      1.000\n",
      " - Min:     -1.000\n",
      " - Mean:    -0.007\n",
      " - Std Dev:  0.719\n",
      "\n",
      "tensor([[-0.0013, -0.0014, -0.0013,  ..., -0.0008, -0.0002, -0.0011]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from audio_utils import play_audio, plot_waveform, print_stats, print_metadata, plot_specgram\n",
    "\n",
    "for filepath in [input_filepath, target_filepath]:\n",
    "    metadata = torchaudio.info(filepath)\n",
    "    print_metadata(metadata, src=filepath)\n",
    "    waveform, _ = torchaudio.load(filepath)\n",
    "    print_stats(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "assert input_waveform.shape == target_waveform.shape\n",
    "frames_count = input_waveform.shape[1]\n",
    "train_frames_count = int(0.8 * frames_count)\n",
    "train_input_waveform = input_waveform[0, :train_frames_count]\n",
    "test_input_waveform = input_waveform[0, train_frames_count:]\n",
    "train_target_waveform = target_waveform[0, :train_frames_count]\n",
    "test_target_waveform = target_waveform[0, train_frames_count:]\n",
    "torchaudio.save('./test_target.wav', test_target_waveform.unsqueeze(0), sample_rate)\n",
    "torchaudio.save('./test_input.wav', test_input_waveform.unsqueeze(0), sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTrajectoryNetworkFF(nn.Module):\n",
    "    def __init__(self, is_trained=False):\n",
    "        super().__init__()\n",
    "        self.densely_connected_layers = nn.Sequential(nn.Linear(2, 8, bias=False), nn.Tanh(), nn.Linear(8, 8, bias=False), nn.Tanh(), nn.Linear(8, 1, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_output = self.densely_connected_layers(x)\n",
    "        output = dense_output[..., 0] + x[..., 1]\n",
    "        return output.unsqueeze(-1)\n",
    "\n",
    "stn = StateTrajectoryNetworkFF(is_trained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTrajectoryNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn1 = nn.RNN(input_size=2, hidden_size=8, num_layers=1, nonlinearity='tanh', batch_first=True)\n",
    "        self.linear = nn.Linear(8, 8)\n",
    "        self.rnn2 = nn.RNN(input_size=8, hidden_size=1, num_layers=1, nonlinearity='tanh', batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output1, hidden1 = self.rnn1(x)\n",
    "        output_linear = torch.tanh(self.linear(output1))\n",
    "        output2, hidden2 = self.rnn2(output_linear)\n",
    "        output3 = output2[..., 0] + x[..., 1]\n",
    "        output3.unsqueeze_(-1)\n",
    "        return output3\n",
    "\n",
    "# stn = StateTrajectoryNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda:0 for training.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StateTrajectoryNetworkFF(\n",
       "  (densely_connected_layers): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=8, bias=False)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=8, out_features=8, bias=False)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=8, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device} for training.')\n",
    "\n",
    "stn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def normalized_mse_loss(output, target):\n",
    "    minimum_value = 1e-5 * torch.ones_like(target)\n",
    "    loss = torch.mean(torch.div((target - output) ** 2, torch.maximum(target ** 2, minimum_value)))\n",
    "    return loss\n",
    "\n",
    "optimizer = optim.Adam(stn.parameters(), lr=0.001)\n",
    "criterion = normalized_mse_loss\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "StateTrajectoryNetworkFF(\n  (densely_connected_layers): Sequential(\n    (0): Linear(in_features=2, out_features=8, bias=False)\n    (1): Tanh()\n    (2): Linear(in_features=8, out_features=8, bias=False)\n    (3): Tanh()\n    (4): Linear(in_features=8, out_features=1, bias=False)\n  )\n)\n<class 'torch.nn.parameter.Parameter'> torch.Size([8, 2])\n<class 'torch.nn.parameter.Parameter'> torch.Size([8, 8])\n<class 'torch.nn.parameter.Parameter'> torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "print(stn)\n",
    "for param in stn.parameters():\n",
    "    print(type(param), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 input minibatch shape: (8251, 2048, 2)\n1 target minibatch shape: (8251, 2048, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "sequence_length = 2048\n",
    "segments_count = train_frames_count // sequence_length\n",
    "input_batch = np.zeros((segments_count, sequence_length, 2))\n",
    "target_batch = np.zeros((segments_count, sequence_length, 1))\n",
    "for i in range(segments_count):\n",
    "    start_id = i * sequence_length\n",
    "    end_id = (i + 1) * sequence_length\n",
    "    input_batch[i, :, 0] = train_input_waveform[start_id:end_id]\n",
    "    input_batch[i, 1:, 1] = train_target_waveform[start_id:end_id-1]\n",
    "    target_batch[i, :, 0] = train_target_waveform[start_id:end_id]\n",
    "\n",
    "print(f'1 input minibatch shape: {input_batch.shape}')\n",
    "print(f'1 target minibatch shape: {target_batch.shape}')\n",
    "\n",
    "input_batch = torch.tensor(input_batch, dtype=torch.float, device=device)\n",
    "target_batch = torch.tensor(target_batch, dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[261,   200] loss: 0.02270\n",
      "[262,   200] loss: 0.02269\n",
      "[263,   200] loss: 0.02268\n",
      "[264,   200] loss: 0.02267\n",
      "[265,   200] loss: 0.02266\n",
      "[266,   200] loss: 0.02264\n",
      "[267,   200] loss: 0.02263\n",
      "[268,   200] loss: 0.02262\n",
      "[269,   200] loss: 0.02261\n",
      "[270,   200] loss: 0.02260\n",
      "[271,   200] loss: 0.02259\n",
      "[272,   200] loss: 0.02257\n",
      "[273,   200] loss: 0.02256\n",
      "[274,   200] loss: 0.02255\n",
      "[275,   200] loss: 0.02254\n",
      "[276,   200] loss: 0.02253\n",
      "[277,   200] loss: 0.02252\n",
      "[278,   200] loss: 0.02250\n",
      "[279,   200] loss: 0.02249\n",
      "[280,   200] loss: 0.02248\n",
      "[281,   200] loss: 0.02247\n",
      "[282,   200] loss: 0.02246\n",
      "[283,   200] loss: 0.02245\n",
      "[284,   200] loss: 0.02243\n",
      "[285,   200] loss: 0.02242\n",
      "[286,   200] loss: 0.02241\n",
      "[287,   200] loss: 0.02240\n",
      "[288,   200] loss: 0.02239\n",
      "[289,   200] loss: 0.02237\n",
      "[290,   200] loss: 0.02236\n",
      "[291,   200] loss: 0.02235\n",
      "[292,   200] loss: 0.02234\n",
      "[293,   200] loss: 0.02233\n",
      "[294,   200] loss: 0.02231\n",
      "[295,   200] loss: 0.02230\n",
      "[296,   200] loss: 0.02229\n",
      "[297,   200] loss: 0.02228\n",
      "[298,   200] loss: 0.02227\n",
      "[299,   200] loss: 0.02226\n",
      "[300,   200] loss: 0.02225\n",
      "[301,   200] loss: 0.02223\n",
      "[302,   200] loss: 0.02222\n",
      "[303,   200] loss: 0.02221\n",
      "[304,   200] loss: 0.02220\n",
      "[305,   200] loss: 0.02219\n",
      "[306,   200] loss: 0.02218\n",
      "[307,   200] loss: 0.02217\n",
      "[308,   200] loss: 0.02216\n",
      "[309,   200] loss: 0.02215\n",
      "[310,   200] loss: 0.02215\n",
      "[311,   200] loss: 0.02214\n",
      "[312,   200] loss: 0.02213\n",
      "[313,   200] loss: 0.02212\n",
      "[314,   200] loss: 0.02211\n",
      "[315,   200] loss: 0.02210\n",
      "[316,   200] loss: 0.02209\n",
      "[317,   200] loss: 0.02208\n",
      "[318,   200] loss: 0.02207\n",
      "[319,   200] loss: 0.02206\n",
      "[320,   200] loss: 0.02205\n",
      "[321,   200] loss: 0.02205\n",
      "[322,   200] loss: 0.02204\n",
      "[323,   200] loss: 0.02203\n",
      "[324,   200] loss: 0.02202\n",
      "[325,   200] loss: 0.02201\n",
      "[326,   200] loss: 0.02201\n",
      "[327,   200] loss: 0.02200\n",
      "[328,   200] loss: 0.02199\n",
      "[329,   200] loss: 0.02198\n",
      "[330,   200] loss: 0.02197\n",
      "[331,   200] loss: 0.02197\n",
      "[332,   200] loss: 0.02196\n",
      "[333,   200] loss: 0.02195\n",
      "[334,   200] loss: 0.02195\n",
      "[335,   200] loss: 0.02194\n",
      "[336,   200] loss: 0.02193\n",
      "[337,   200] loss: 0.02192\n",
      "[338,   200] loss: 0.02192\n",
      "[339,   200] loss: 0.02191\n",
      "[340,   200] loss: 0.02190\n",
      "[341,   200] loss: 0.02190\n",
      "[342,   200] loss: 0.02189\n",
      "[343,   200] loss: 0.02189\n",
      "[344,   200] loss: 0.02188\n",
      "[345,   200] loss: 0.02187\n",
      "[346,   200] loss: 0.02187\n",
      "[347,   200] loss: 0.02186\n",
      "[348,   200] loss: 0.02186\n",
      "[349,   200] loss: 0.02185\n",
      "[350,   200] loss: 0.02185\n",
      "[351,   200] loss: 0.02184\n",
      "[352,   200] loss: 0.02183\n",
      "[353,   200] loss: 0.02183\n",
      "[354,   200] loss: 0.02182\n",
      "[355,   200] loss: 0.02182\n",
      "[356,   200] loss: 0.02181\n",
      "[357,   200] loss: 0.02181\n",
      "[358,   200] loss: 0.02180\n",
      "[359,   200] loss: 0.02180\n",
      "[360,   200] loss: 0.02179\n",
      "[361,   200] loss: 0.02179\n",
      "[362,   200] loss: 0.02179\n",
      "[363,   200] loss: 0.02178\n",
      "[364,   200] loss: 0.02178\n",
      "[365,   200] loss: 0.02177\n",
      "[366,   200] loss: 0.02177\n",
      "[367,   200] loss: 0.02176\n",
      "[368,   200] loss: 0.02176\n",
      "[369,   200] loss: 0.02176\n",
      "[370,   200] loss: 0.02175\n",
      "[371,   200] loss: 0.02175\n",
      "[372,   200] loss: 0.02174\n",
      "[373,   200] loss: 0.02174\n",
      "[374,   200] loss: 0.02174\n",
      "[375,   200] loss: 0.02173\n",
      "[376,   200] loss: 0.02173\n",
      "[377,   200] loss: 0.02173\n",
      "[378,   200] loss: 0.02172\n",
      "[379,   200] loss: 0.02172\n",
      "[380,   200] loss: 0.02172\n",
      "[381,   200] loss: 0.02171\n",
      "[382,   200] loss: 0.02171\n",
      "[383,   200] loss: 0.02171\n",
      "[384,   200] loss: 0.02170\n",
      "[385,   200] loss: 0.02170\n",
      "[386,   200] loss: 0.02170\n",
      "[387,   200] loss: 0.02170\n",
      "[388,   200] loss: 0.02169\n",
      "[389,   200] loss: 0.02169\n",
      "[390,   200] loss: 0.02169\n",
      "[391,   200] loss: 0.02168\n",
      "[392,   200] loss: 0.02168\n",
      "[393,   200] loss: 0.02168\n",
      "[394,   200] loss: 0.02168\n",
      "[395,   200] loss: 0.02167\n",
      "[396,   200] loss: 0.02167\n",
      "[397,   200] loss: 0.02167\n",
      "[398,   200] loss: 0.02167\n",
      "[399,   200] loss: 0.02166\n",
      "[400,   200] loss: 0.02166\n",
      "[401,   200] loss: 0.02166\n",
      "[402,   200] loss: 0.02166\n",
      "[403,   200] loss: 0.02165\n",
      "[404,   200] loss: 0.02165\n",
      "[405,   200] loss: 0.02165\n",
      "[406,   200] loss: 0.02165\n",
      "[407,   200] loss: 0.02165\n",
      "[408,   200] loss: 0.02164\n",
      "[409,   200] loss: 0.02164\n",
      "[410,   200] loss: 0.02164\n",
      "[411,   200] loss: 0.02164\n",
      "[412,   200] loss: 0.02164\n",
      "[413,   200] loss: 0.02163\n",
      "[414,   200] loss: 0.02163\n",
      "[415,   200] loss: 0.02163\n",
      "[416,   200] loss: 0.02163\n",
      "[417,   200] loss: 0.02163\n",
      "[418,   200] loss: 0.02162\n",
      "[419,   200] loss: 0.02162\n",
      "[420,   200] loss: 0.02162\n",
      "[421,   200] loss: 0.02162\n",
      "[422,   200] loss: 0.02162\n",
      "[423,   200] loss: 0.02162\n",
      "[424,   200] loss: 0.02161\n",
      "[425,   200] loss: 0.02161\n",
      "[426,   200] loss: 0.02161\n",
      "[427,   200] loss: 0.02161\n",
      "[428,   200] loss: 0.02161\n",
      "[429,   200] loss: 0.02161\n",
      "[430,   200] loss: 0.02160\n",
      "[431,   200] loss: 0.02160\n",
      "[432,   200] loss: 0.02160\n",
      "[433,   200] loss: 0.02160\n",
      "[434,   200] loss: 0.02160\n",
      "[435,   200] loss: 0.02160\n",
      "[436,   200] loss: 0.02159\n",
      "[437,   200] loss: 0.02159\n",
      "[438,   200] loss: 0.02159\n",
      "[439,   200] loss: 0.02159\n",
      "[440,   200] loss: 0.02159\n",
      "[441,   200] loss: 0.02159\n",
      "[442,   200] loss: 0.02159\n",
      "[443,   200] loss: 0.02158\n",
      "[444,   200] loss: 0.02158\n",
      "[445,   200] loss: 0.02158\n",
      "[446,   200] loss: 0.02158\n",
      "[447,   200] loss: 0.02158\n",
      "[448,   200] loss: 0.02158\n",
      "[449,   200] loss: 0.02158\n",
      "[450,   200] loss: 0.02157\n",
      "[451,   200] loss: 0.02157\n",
      "[452,   200] loss: 0.02157\n",
      "[453,   200] loss: 0.02157\n",
      "[454,   200] loss: 0.02157\n",
      "[455,   200] loss: 0.02157\n",
      "[456,   200] loss: 0.02157\n",
      "[457,   200] loss: 0.02157\n",
      "[458,   200] loss: 0.02156\n",
      "[459,   200] loss: 0.02156\n",
      "[460,   200] loss: 0.02156\n",
      "[461,   200] loss: 0.02156\n",
      "[462,   200] loss: 0.02156\n",
      "[463,   200] loss: 0.02156\n",
      "[464,   200] loss: 0.02156\n",
      "[465,   200] loss: 0.02156\n",
      "[466,   200] loss: 0.02155\n",
      "[467,   200] loss: 0.02155\n",
      "[468,   200] loss: 0.02155\n",
      "[469,   200] loss: 0.02155\n",
      "[470,   200] loss: 0.02155\n",
      "[471,   200] loss: 0.02155\n",
      "[472,   200] loss: 0.02155\n",
      "[473,   200] loss: 0.02155\n",
      "[474,   200] loss: 0.02154\n",
      "[475,   200] loss: 0.02154\n",
      "[476,   200] loss: 0.02154\n",
      "[477,   200] loss: 0.02154\n",
      "[478,   200] loss: 0.02154\n",
      "[479,   200] loss: 0.02154\n",
      "[480,   200] loss: 0.02154\n",
      "[481,   200] loss: 0.02154\n",
      "[482,   200] loss: 0.02154\n",
      "[483,   200] loss: 0.02153\n",
      "[484,   200] loss: 0.02153\n",
      "[485,   200] loss: 0.02153\n",
      "[486,   200] loss: 0.02153\n",
      "[487,   200] loss: 0.02153\n",
      "[488,   200] loss: 0.02153\n",
      "[489,   200] loss: 0.02153\n",
      "[490,   200] loss: 0.02153\n",
      "[491,   200] loss: 0.02152\n",
      "[492,   200] loss: 0.02152\n",
      "[493,   200] loss: 0.02152\n",
      "[494,   200] loss: 0.02152\n",
      "[495,   200] loss: 0.02152\n",
      "[496,   200] loss: 0.02152\n",
      "[497,   200] loss: 0.02152\n",
      "[498,   200] loss: 0.02152\n",
      "[499,   200] loss: 0.02152\n",
      "[500,   200] loss: 0.02151\n",
      "[501,   200] loss: 0.02151\n",
      "[502,   200] loss: 0.02151\n",
      "[503,   200] loss: 0.02151\n",
      "[504,   200] loss: 0.02151\n",
      "[505,   200] loss: 0.02151\n",
      "[506,   200] loss: 0.02151\n",
      "[507,   200] loss: 0.02151\n",
      "[508,   200] loss: 0.02150\n",
      "[509,   200] loss: 0.02150\n",
      "[510,   200] loss: 0.02150\n",
      "[511,   200] loss: 0.02150\n",
      "[512,   200] loss: 0.02150\n",
      "[513,   200] loss: 0.02150\n",
      "[514,   200] loss: 0.02150\n",
      "[515,   200] loss: 0.02150\n",
      "[516,   200] loss: 0.02149\n",
      "[517,   200] loss: 0.02149\n",
      "[518,   200] loss: 0.02149\n",
      "[519,   200] loss: 0.02149\n",
      "[520,   200] loss: 0.02149\n",
      "[521,   200] loss: 0.02149\n",
      "[522,   200] loss: 0.02149\n",
      "[523,   200] loss: 0.02149\n",
      "[524,   200] loss: 0.02148\n",
      "[525,   200] loss: 0.02148\n",
      "[526,   200] loss: 0.02148\n",
      "[527,   200] loss: 0.02148\n",
      "[528,   200] loss: 0.02148\n",
      "[529,   200] loss: 0.02148\n",
      "[530,   200] loss: 0.02147\n",
      "[531,   200] loss: 0.02148\n",
      "[532,   200] loss: 0.02147\n",
      "[533,   200] loss: 0.02147\n",
      "[534,   200] loss: 0.02147\n",
      "[535,   200] loss: 0.02147\n",
      "[536,   200] loss: 0.02147\n",
      "[537,   200] loss: 0.02147\n",
      "[538,   200] loss: 0.02147\n",
      "[539,   200] loss: 0.02147\n",
      "[540,   200] loss: 0.02147\n",
      "[541,   200] loss: 0.02147\n",
      "[542,   200] loss: 0.02146\n",
      "[543,   200] loss: 0.02147\n",
      "[544,   200] loss: 0.02146\n",
      "[545,   200] loss: 0.02146\n",
      "[546,   200] loss: 0.02146\n",
      "[547,   200] loss: 0.02146\n",
      "[548,   200] loss: 0.02146\n",
      "[549,   200] loss: 0.02146\n",
      "[550,   200] loss: 0.02146\n",
      "[551,   200] loss: 0.02146\n",
      "[552,   200] loss: 0.02146\n",
      "[553,   200] loss: 0.02146\n",
      "[554,   200] loss: 0.02146\n",
      "[555,   200] loss: 0.02146\n",
      "[556,   200] loss: 0.02145\n",
      "[557,   200] loss: 0.02145\n",
      "[558,   200] loss: 0.02145\n",
      "[559,   200] loss: 0.02145\n",
      "[560,   200] loss: 0.02145\n",
      "[561,   200] loss: 0.02145\n",
      "[562,   200] loss: 0.02145\n",
      "[563,   200] loss: 0.02145\n",
      "[564,   200] loss: 0.02145\n",
      "[565,   200] loss: 0.02145\n",
      "[566,   200] loss: 0.02145\n",
      "[567,   200] loss: 0.02145\n",
      "[568,   200] loss: 0.02145\n",
      "[569,   200] loss: 0.02145\n",
      "[570,   200] loss: 0.02144\n",
      "[571,   200] loss: 0.02145\n",
      "[572,   200] loss: 0.02144\n",
      "[573,   200] loss: 0.02144\n",
      "[574,   200] loss: 0.02144\n",
      "[575,   200] loss: 0.02144\n",
      "[576,   200] loss: 0.02144\n",
      "[577,   200] loss: 0.02144\n",
      "[578,   200] loss: 0.02144\n",
      "[579,   200] loss: 0.02144\n",
      "[580,   200] loss: 0.02144\n",
      "[581,   200] loss: 0.02144\n",
      "[582,   200] loss: 0.02144\n",
      "[583,   200] loss: 0.02144\n",
      "[584,   200] loss: 0.02144\n",
      "[585,   200] loss: 0.02144\n",
      "[586,   200] loss: 0.02143\n",
      "[587,   200] loss: 0.02143\n",
      "[588,   200] loss: 0.02143\n",
      "[589,   200] loss: 0.02143\n",
      "[590,   200] loss: 0.02143\n",
      "[591,   200] loss: 0.02143\n",
      "[592,   200] loss: 0.02143\n",
      "[593,   200] loss: 0.02143\n",
      "[594,   200] loss: 0.02143\n",
      "[595,   200] loss: 0.02143\n",
      "[596,   200] loss: 0.02143\n",
      "[597,   200] loss: 0.02143\n",
      "[598,   200] loss: 0.02143\n",
      "[599,   200] loss: 0.02143\n",
      "[600,   200] loss: 0.02143\n",
      "[601,   200] loss: 0.02143\n",
      "[602,   200] loss: 0.02142\n",
      "[603,   200] loss: 0.02142\n",
      "[604,   200] loss: 0.02142\n",
      "[605,   200] loss: 0.02142\n",
      "[606,   200] loss: 0.02142\n",
      "[607,   200] loss: 0.02142\n",
      "[608,   200] loss: 0.02142\n",
      "[609,   200] loss: 0.02142\n",
      "[610,   200] loss: 0.02142\n",
      "[611,   200] loss: 0.02142\n",
      "[612,   200] loss: 0.02142\n",
      "[613,   200] loss: 0.02142\n",
      "[614,   200] loss: 0.02142\n",
      "[615,   200] loss: 0.02142\n",
      "[616,   200] loss: 0.02142\n",
      "[617,   200] loss: 0.02142\n",
      "[618,   200] loss: 0.02141\n",
      "[619,   200] loss: 0.02142\n",
      "[620,   200] loss: 0.02141\n",
      "[621,   200] loss: 0.02141\n",
      "[622,   200] loss: 0.02141\n",
      "[623,   200] loss: 0.02141\n",
      "[624,   200] loss: 0.02141\n",
      "[625,   200] loss: 0.02141\n",
      "[626,   200] loss: 0.02141\n",
      "[627,   200] loss: 0.02141\n",
      "[628,   200] loss: 0.02141\n",
      "[629,   200] loss: 0.02141\n",
      "[630,   200] loss: 0.02141\n",
      "[631,   200] loss: 0.02141\n",
      "[632,   200] loss: 0.02141\n",
      "[633,   200] loss: 0.02141\n",
      "[634,   200] loss: 0.02141\n",
      "[635,   200] loss: 0.02141\n",
      "[636,   200] loss: 0.02140\n",
      "[637,   200] loss: 0.02140\n",
      "[638,   200] loss: 0.02140\n",
      "[639,   200] loss: 0.02140\n",
      "[640,   200] loss: 0.02140\n",
      "[641,   200] loss: 0.02140\n",
      "[642,   200] loss: 0.02140\n",
      "[643,   200] loss: 0.02140\n",
      "[644,   200] loss: 0.02140\n",
      "[645,   200] loss: 0.02140\n",
      "[646,   200] loss: 0.02140\n",
      "[647,   200] loss: 0.02140\n",
      "[648,   200] loss: 0.02140\n",
      "[649,   200] loss: 0.02140\n",
      "[650,   200] loss: 0.02140\n",
      "[651,   200] loss: 0.02140\n",
      "[652,   200] loss: 0.02140\n",
      "[653,   200] loss: 0.02140\n",
      "[654,   200] loss: 0.02139\n",
      "[655,   200] loss: 0.02140\n",
      "[656,   200] loss: 0.02139\n",
      "[657,   200] loss: 0.02139\n",
      "[658,   200] loss: 0.02139\n",
      "[659,   200] loss: 0.02139\n",
      "[660,   200] loss: 0.02139\n",
      "[661,   200] loss: 0.02139\n",
      "[662,   200] loss: 0.02139\n",
      "[663,   200] loss: 0.02139\n",
      "[664,   200] loss: 0.02139\n",
      "[665,   200] loss: 0.02139\n",
      "[666,   200] loss: 0.02139\n",
      "[667,   200] loss: 0.02139\n",
      "[668,   200] loss: 0.02139\n",
      "[669,   200] loss: 0.02139\n",
      "[670,   200] loss: 0.02139\n",
      "[671,   200] loss: 0.02139\n",
      "[672,   200] loss: 0.02139\n",
      "[673,   200] loss: 0.02139\n",
      "[674,   200] loss: 0.02138\n",
      "[675,   200] loss: 0.02138\n",
      "[676,   200] loss: 0.02138\n",
      "[677,   200] loss: 0.02138\n",
      "[678,   200] loss: 0.02138\n",
      "[679,   200] loss: 0.02138\n",
      "[680,   200] loss: 0.02138\n",
      "[681,   200] loss: 0.02138\n",
      "[682,   200] loss: 0.02138\n",
      "[683,   200] loss: 0.02138\n",
      "[684,   200] loss: 0.02138\n",
      "[685,   200] loss: 0.02138\n",
      "[686,   200] loss: 0.02138\n",
      "[687,   200] loss: 0.02138\n",
      "[688,   200] loss: 0.02138\n",
      "[689,   200] loss: 0.02138\n",
      "[690,   200] loss: 0.02138\n",
      "[691,   200] loss: 0.02138\n",
      "[692,   200] loss: 0.02138\n",
      "[693,   200] loss: 0.02138\n",
      "[694,   200] loss: 0.02138\n",
      "[695,   200] loss: 0.02138\n",
      "[696,   200] loss: 0.02137\n",
      "[697,   200] loss: 0.02137\n",
      "[698,   200] loss: 0.02137\n",
      "[699,   200] loss: 0.02137\n",
      "[700,   200] loss: 0.02137\n",
      "[701,   200] loss: 0.02137\n",
      "[702,   200] loss: 0.02137\n",
      "[703,   200] loss: 0.02137\n",
      "[704,   200] loss: 0.02137\n",
      "[705,   200] loss: 0.02137\n",
      "[706,   200] loss: 0.02137\n",
      "[707,   200] loss: 0.02137\n",
      "[708,   200] loss: 0.02137\n",
      "[709,   200] loss: 0.02137\n",
      "[710,   200] loss: 0.02137\n",
      "[711,   200] loss: 0.02137\n",
      "[712,   200] loss: 0.02137\n",
      "[713,   200] loss: 0.02137\n",
      "[714,   200] loss: 0.02137\n",
      "[715,   200] loss: 0.02137\n",
      "[716,   200] loss: 0.02137\n",
      "[717,   200] loss: 0.02137\n",
      "[718,   200] loss: 0.02136\n",
      "[719,   200] loss: 0.02136\n",
      "[720,   200] loss: 0.02136\n",
      "[721,   200] loss: 0.02136\n",
      "[722,   200] loss: 0.02136\n",
      "[723,   200] loss: 0.02136\n",
      "[724,   200] loss: 0.02136\n",
      "[725,   200] loss: 0.02136\n",
      "[726,   200] loss: 0.02136\n",
      "[727,   200] loss: 0.02136\n",
      "[728,   200] loss: 0.02136\n",
      "[729,   200] loss: 0.02136\n",
      "[730,   200] loss: 0.02136\n",
      "[731,   200] loss: 0.02136\n",
      "[732,   200] loss: 0.02136\n",
      "[733,   200] loss: 0.02136\n",
      "[734,   200] loss: 0.02136\n",
      "[735,   200] loss: 0.02136\n",
      "[736,   200] loss: 0.02136\n",
      "[737,   200] loss: 0.02136\n",
      "[738,   200] loss: 0.02136\n",
      "[739,   200] loss: 0.02136\n",
      "[740,   200] loss: 0.02136\n",
      "[741,   200] loss: 0.02136\n",
      "[742,   200] loss: 0.02135\n",
      "[743,   200] loss: 0.02135\n",
      "[744,   200] loss: 0.02135\n",
      "[745,   200] loss: 0.02135\n",
      "[746,   200] loss: 0.02135\n",
      "[747,   200] loss: 0.02135\n",
      "[748,   200] loss: 0.02135\n",
      "[749,   200] loss: 0.02135\n",
      "[750,   200] loss: 0.02135\n",
      "[751,   200] loss: 0.02135\n",
      "[752,   200] loss: 0.02135\n",
      "[753,   200] loss: 0.02135\n",
      "[754,   200] loss: 0.02135\n",
      "[755,   200] loss: 0.02135\n",
      "[756,   200] loss: 0.02135\n",
      "[757,   200] loss: 0.02135\n",
      "[758,   200] loss: 0.02135\n",
      "[759,   200] loss: 0.02135\n",
      "[760,   200] loss: 0.02135\n",
      "[761,   200] loss: 0.02135\n",
      "[762,   200] loss: 0.02135\n",
      "[763,   200] loss: 0.02135\n",
      "[764,   200] loss: 0.02135\n",
      "[765,   200] loss: 0.02135\n",
      "[766,   200] loss: 0.02135\n",
      "[767,   200] loss: 0.02135\n",
      "[768,   200] loss: 0.02135\n",
      "[769,   200] loss: 0.02134\n",
      "[770,   200] loss: 0.02134\n",
      "[771,   200] loss: 0.02134\n",
      "[772,   200] loss: 0.02134\n",
      "[773,   200] loss: 0.02134\n",
      "[774,   200] loss: 0.02134\n",
      "[775,   200] loss: 0.02134\n",
      "[776,   200] loss: 0.02134\n",
      "[777,   200] loss: 0.02134\n",
      "[778,   200] loss: 0.02134\n",
      "[779,   200] loss: 0.02134\n",
      "[780,   200] loss: 0.02134\n",
      "[781,   200] loss: 0.02134\n",
      "[782,   200] loss: 0.02134\n",
      "[783,   200] loss: 0.02134\n",
      "[784,   200] loss: 0.02134\n",
      "[785,   200] loss: 0.02134\n",
      "[786,   200] loss: 0.02134\n",
      "[787,   200] loss: 0.02134\n",
      "[788,   200] loss: 0.02134\n",
      "[789,   200] loss: 0.02134\n",
      "[790,   200] loss: 0.02134\n",
      "[791,   200] loss: 0.02134\n",
      "[792,   200] loss: 0.02134\n",
      "[793,   200] loss: 0.02134\n",
      "[794,   200] loss: 0.02134\n",
      "[795,   200] loss: 0.02134\n",
      "[796,   200] loss: 0.02134\n",
      "[797,   200] loss: 0.02133\n",
      "[798,   200] loss: 0.02133\n",
      "[799,   200] loss: 0.02133\n",
      "[800,   200] loss: 0.02133\n",
      "[801,   200] loss: 0.02133\n",
      "[802,   200] loss: 0.02133\n",
      "[803,   200] loss: 0.02133\n",
      "[804,   200] loss: 0.02133\n",
      "[805,   200] loss: 0.02133\n",
      "[806,   200] loss: 0.02133\n",
      "[807,   200] loss: 0.02133\n",
      "[808,   200] loss: 0.02133\n",
      "[809,   200] loss: 0.02133\n",
      "[810,   200] loss: 0.02133\n",
      "[811,   200] loss: 0.02133\n",
      "[812,   200] loss: 0.02133\n",
      "[813,   200] loss: 0.02133\n",
      "[814,   200] loss: 0.02133\n",
      "[815,   200] loss: 0.02133\n",
      "[816,   200] loss: 0.02133\n",
      "[817,   200] loss: 0.02133\n",
      "[818,   200] loss: 0.02133\n",
      "[819,   200] loss: 0.02133\n",
      "[820,   200] loss: 0.02133\n",
      "[821,   200] loss: 0.02133\n",
      "[822,   200] loss: 0.02133\n",
      "[823,   200] loss: 0.02133\n",
      "[824,   200] loss: 0.02133\n",
      "[825,   200] loss: 0.02133\n",
      "[826,   200] loss: 0.02133\n",
      "[827,   200] loss: 0.02133\n",
      "[828,   200] loss: 0.02133\n",
      "[829,   200] loss: 0.02132\n",
      "[830,   200] loss: 0.02132\n",
      "[831,   200] loss: 0.02132\n",
      "[832,   200] loss: 0.02132\n",
      "[833,   200] loss: 0.02132\n",
      "[834,   200] loss: 0.02132\n",
      "[835,   200] loss: 0.02132\n",
      "[836,   200] loss: 0.02132\n",
      "[837,   200] loss: 0.02132\n",
      "[838,   200] loss: 0.02132\n",
      "[839,   200] loss: 0.02132\n",
      "[840,   200] loss: 0.02132\n",
      "[841,   200] loss: 0.02132\n",
      "[842,   200] loss: 0.02132\n",
      "[843,   200] loss: 0.02132\n",
      "[844,   200] loss: 0.02132\n",
      "[845,   200] loss: 0.02132\n",
      "[846,   200] loss: 0.02132\n",
      "[847,   200] loss: 0.02132\n",
      "[848,   200] loss: 0.02132\n",
      "[849,   200] loss: 0.02132\n",
      "[850,   200] loss: 0.02132\n",
      "[851,   200] loss: 0.02132\n",
      "[852,   200] loss: 0.02132\n",
      "[853,   200] loss: 0.02132\n",
      "[854,   200] loss: 0.02132\n",
      "[855,   200] loss: 0.02132\n",
      "[856,   200] loss: 0.02132\n",
      "[857,   200] loss: 0.02132\n",
      "[858,   200] loss: 0.02132\n",
      "[859,   200] loss: 0.02132\n",
      "[860,   200] loss: 0.02132\n",
      "[861,   200] loss: 0.02132\n",
      "[862,   200] loss: 0.02132\n",
      "[863,   200] loss: 0.02131\n",
      "[864,   200] loss: 0.02131\n",
      "[865,   200] loss: 0.02131\n",
      "[866,   200] loss: 0.02131\n",
      "[867,   200] loss: 0.02131\n",
      "[868,   200] loss: 0.02131\n",
      "[869,   200] loss: 0.02131\n",
      "[870,   200] loss: 0.02131\n",
      "[871,   200] loss: 0.02131\n",
      "[872,   200] loss: 0.02131\n",
      "[873,   200] loss: 0.02131\n",
      "[874,   200] loss: 0.02131\n",
      "[875,   200] loss: 0.02131\n",
      "[876,   200] loss: 0.02131\n",
      "[877,   200] loss: 0.02131\n",
      "[878,   200] loss: 0.02131\n",
      "[879,   200] loss: 0.02131\n",
      "[880,   200] loss: 0.02131\n",
      "[881,   200] loss: 0.02131\n",
      "[882,   200] loss: 0.02131\n",
      "[883,   200] loss: 0.02131\n",
      "[884,   200] loss: 0.02131\n",
      "[885,   200] loss: 0.02131\n",
      "[886,   200] loss: 0.02131\n",
      "[887,   200] loss: 0.02131\n",
      "[888,   200] loss: 0.02131\n",
      "[889,   200] loss: 0.02131\n",
      "[890,   200] loss: 0.02131\n",
      "[891,   200] loss: 0.02131\n",
      "[892,   200] loss: 0.02131\n",
      "[893,   200] loss: 0.02131\n",
      "[894,   200] loss: 0.02131\n",
      "[895,   200] loss: 0.02131\n",
      "[896,   200] loss: 0.02131\n",
      "[897,   200] loss: 0.02131\n",
      "[898,   200] loss: 0.02131\n",
      "[899,   200] loss: 0.02131\n",
      "[900,   200] loss: 0.02131\n",
      "[901,   200] loss: 0.02131\n",
      "[902,   200] loss: 0.02130\n",
      "[903,   200] loss: 0.02130\n",
      "[904,   200] loss: 0.02130\n",
      "[905,   200] loss: 0.02130\n",
      "[906,   200] loss: 0.02130\n",
      "[907,   200] loss: 0.02130\n",
      "[908,   200] loss: 0.02130\n",
      "[909,   200] loss: 0.02130\n",
      "[910,   200] loss: 0.02130\n",
      "[911,   200] loss: 0.02130\n",
      "[912,   200] loss: 0.02130\n",
      "[913,   200] loss: 0.02130\n",
      "[914,   200] loss: 0.02130\n",
      "[915,   200] loss: 0.02130\n",
      "[916,   200] loss: 0.02130\n",
      "[917,   200] loss: 0.02130\n",
      "[918,   200] loss: 0.02130\n",
      "[919,   200] loss: 0.02130\n",
      "[920,   200] loss: 0.02130\n",
      "[921,   200] loss: 0.02130\n",
      "[922,   200] loss: 0.02130\n",
      "[923,   200] loss: 0.02130\n",
      "[924,   200] loss: 0.02130\n",
      "[925,   200] loss: 0.02130\n",
      "[926,   200] loss: 0.02130\n",
      "[927,   200] loss: 0.02130\n",
      "[928,   200] loss: 0.02130\n",
      "[929,   200] loss: 0.02130\n",
      "[930,   200] loss: 0.02130\n",
      "[931,   200] loss: 0.02130\n",
      "[932,   200] loss: 0.02130\n",
      "[933,   200] loss: 0.02130\n",
      "[934,   200] loss: 0.02130\n",
      "[935,   200] loss: 0.02130\n",
      "[936,   200] loss: 0.02130\n",
      "[937,   200] loss: 0.02130\n",
      "[938,   200] loss: 0.02130\n",
      "[939,   200] loss: 0.02130\n",
      "[940,   200] loss: 0.02130\n",
      "[941,   200] loss: 0.02130\n",
      "[942,   200] loss: 0.02130\n",
      "[943,   200] loss: 0.02130\n",
      "[944,   200] loss: 0.02130\n",
      "[945,   200] loss: 0.02129\n",
      "[946,   200] loss: 0.02129\n",
      "[947,   200] loss: 0.02129\n",
      "[948,   200] loss: 0.02129\n",
      "[949,   200] loss: 0.02129\n",
      "[950,   200] loss: 0.02129\n",
      "[951,   200] loss: 0.02129\n",
      "[952,   200] loss: 0.02129\n",
      "[953,   200] loss: 0.02129\n",
      "[954,   200] loss: 0.02129\n",
      "[955,   200] loss: 0.02129\n",
      "[956,   200] loss: 0.02129\n",
      "[957,   200] loss: 0.02129\n",
      "[958,   200] loss: 0.02129\n",
      "[959,   200] loss: 0.02129\n",
      "[960,   200] loss: 0.02129\n",
      "[961,   200] loss: 0.02129\n",
      "[962,   200] loss: 0.02129\n",
      "[963,   200] loss: 0.02129\n",
      "[964,   200] loss: 0.02129\n",
      "[965,   200] loss: 0.02129\n",
      "[966,   200] loss: 0.02129\n",
      "[967,   200] loss: 0.02129\n",
      "[968,   200] loss: 0.02129\n",
      "[969,   200] loss: 0.02129\n",
      "[970,   200] loss: 0.02129\n",
      "[971,   200] loss: 0.02129\n",
      "[972,   200] loss: 0.02129\n",
      "[973,   200] loss: 0.02129\n",
      "[974,   200] loss: 0.02129\n",
      "[975,   200] loss: 0.02129\n",
      "[976,   200] loss: 0.02129\n",
      "[977,   200] loss: 0.02129\n",
      "[978,   200] loss: 0.02129\n",
      "[979,   200] loss: 0.02129\n",
      "[980,   200] loss: 0.02129\n",
      "[981,   200] loss: 0.02129\n",
      "[982,   200] loss: 0.02129\n",
      "[983,   200] loss: 0.02129\n",
      "[984,   200] loss: 0.02129\n",
      "[985,   200] loss: 0.02129\n",
      "[986,   200] loss: 0.02129\n",
      "[987,   200] loss: 0.02129\n",
      "[988,   200] loss: 0.02129\n",
      "[989,   200] loss: 0.02129\n",
      "[990,   200] loss: 0.02129\n",
      "[991,   200] loss: 0.02128\n",
      "[992,   200] loss: 0.02128\n",
      "[993,   200] loss: 0.02128\n",
      "[994,   200] loss: 0.02128\n",
      "[995,   200] loss: 0.02128\n",
      "[996,   200] loss: 0.02128\n",
      "[997,   200] loss: 0.02128\n",
      "[998,   200] loss: 0.02128\n",
      "[999,   200] loss: 0.02128\n",
      "[1000,   200] loss: 0.02128\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 1000\n",
    "print_loss_every = 200\n",
    "segments_in_a_batch = 40\n",
    "batch_count = segments_count // segments_in_a_batch\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i in range(batch_count):\n",
    "        input_minibatch = input_batch[i*segments_in_a_batch:(i+1)*segments_in_a_batch, :, :]\n",
    "        target_minibatch = target_batch[i*segments_in_a_batch:(i+1)*segments_in_a_batch, :, :]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_minibatch = stn(input_minibatch)\n",
    "\n",
    "        loss = criterion(output_minibatch, target_minibatch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % print_loss_every == print_loss_every - 1:\n",
    "            print('[%d, %5d] loss: %.5f' % (epoch + 1, i + 1, running_loss/print_loss_every))\n",
    "            running_loss = 0.\n",
    "\n",
    "print('Finished training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './diode_clipper_2x8tanhRNN.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(stn.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "stn.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing test data...\n",
      "100%|██████████| 4224781/4224781 [19:18<00:00, 3647.78it/s]Test loss: 0.13651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 1 batch, 1-element sequence, 2 variables (input and state, i.e., previous output)\n",
    "stn = stn.cpu()\n",
    "input_vector = torch.zeros((1, 1, 2), dtype=torch.float)\n",
    "output_vector = torch.zeros((1, 1, 1), dtype=torch.float)\n",
    "test_output = torch.zeros_like(test_input_waveform.to('cpu'))\n",
    "\n",
    "print('Processing test data...')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, sample in tqdm(enumerate(test_input_waveform), total=test_input_waveform.shape[0]):\n",
    "        input_vector[0, 0, 0] = sample\n",
    "        input_vector[0, 0, 1] = output_vector[0, 0, 0]\n",
    "\n",
    "        output_vector = stn(input_vector)\n",
    "\n",
    "        test_output[i] = output_vector[0, 0, 0]\n",
    "\n",
    "    test_loss = criterion(test_output, test_target_waveform)\n",
    "    print(f'Test loss: {test_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape: (1, 4224781)\n",
      "Dtype: torch.float32\n",
      " - Max:      1.026\n",
      " - Min:     -1.026\n",
      " - Mean:     0.020\n",
      " - Std Dev:  0.674\n",
      "\n",
      "tensor([[ 0.5250,  0.7531,  0.8579,  ..., -0.0019,  0.0009, -0.0019]])\n",
      "\n",
      "Shape: (1, 4224781)\n",
      "Dtype: torch.float32\n",
      " - Max:      1.000\n",
      " - Min:     -1.000\n",
      " - Mean:     0.019\n",
      " - Std Dev:  0.657\n",
      "\n",
      "tensor([[ 0.5118,  0.7342,  0.8363,  ..., -0.0018,  0.0009, -0.0018]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_stats(test_output.unsqueeze(0))\n",
    "test_output /= torch.amax(torch.abs(test_output))\n",
    "print_stats(test_output.unsqueeze(0))\n",
    "torchaudio.save('./test_output.wav', test_output.unsqueeze(0), sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}