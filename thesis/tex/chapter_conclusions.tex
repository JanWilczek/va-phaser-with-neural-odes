%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Summary and Conclusions}
\label{chapter:conclusions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The aim of this work was to investigate whether the ODENet framework--teaching a neural network the \acl{ODE} that governs a dynamical system and then supplying it to a numerical solver of choice--can be used for \acl{VA} modeling. If the answer was positive, possible advantages and disadvantages in comparison to other modeling methods were to be investigated.

Ultimately, the answer to this question turned out to be only partially positive. It has been proven on the example of the diode clipper that the ODENet architecture can learn the \ac{ODE} governing a dynamical system. A significant advantage of the learned derivative over an analytical one is the lack of aliasing (unless it is present in the training data). Consequently, there is no need for time- and memory-expensive oversampling.

Furthermore, the learned derivative can with success be used at sampling rates higher than the training sampling rate. However, ODENet outperforms other models in that regard only for significantly higher sampling rates, i.e., four times larger than the training sampling rate.

It has also been proven that in the context of \ac{VA} modeling, ODENet can provide results comparable to the established recurrent architectures like the \ac{LSTM} albeit with a smaller number of parameters.

Taking the above into consideration, there is a potential for real-time implementations of \ac{DAW} plugins using ODENet architecture. With proper code optimization, ODENet probably could be faster than the state-of-the-art \ac{LSTM} architecture. Since during real-time processing, the computation time must be strictly bounded, most likely explicit solvers would need to be used as the implicit methods cannot guarantee fixed convergence time per sample.

However, there is no proof that using a more accurate solver can replace a model with a larger capacity. In fact, all tested solvers differed solely in terms of processing time. Much more can be gained in terms of accuracy by investing time into proper derivative network treatment, i.e., regularization via learning rate schedules, weight decay, etc.

It remains yet to be answered, whether ODENet is suited for modeling time-variant systems like the phaser. Although augmenting the state vector with latent (unobserved) states and using a time-frequency-domain loss function enabled more accurate learning (with the latter yielding improvement even in the baseline architecture), the performance of the derivative network-numerical solver pair is still far behind the baseline \ac{LSTM}. The inferior modeling accuracy persists despite the use of significant number of parameters in the derivative \ac{MLP} (10 times more than the baseline).

Taking a different perspective, one can state that ODENet managed to learn a derivative from data, whose closed-form solution is known (the diode clipper experiment). Currently, there exists no proof that the ODENet could learn the derivative of a dynamical system for which no closed-form solution is known.

In summary, the ODENet is a promising framework for consideration in the context of \ac{VA} modeling but its usefulness in this area remains an open question.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}
\label{sec:future_work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This work verified the applicability of the ODENet framework for simple \ac{VA} models (like the diode clipper) but not for complicated ones (like the phaser). Over the course of work, various ideas to improve the ODENet in the latter came up. The successful ones, i.e., time-frequency-domain loss function and state augmentation were discussed in this thesis. However, there remain many more paths that can be followed to facilitate the goal of \ac{VA} modeling with the proposed methodology.

Since ODENet was successful in modeling systems with a known closed-form derivative (the diode clipper, also \cite{Chen2018,Karlsson2019}), there is a good chance that it could be successful in replacing known white-box models of audio effects. The possibility to compare the learned derivative with an analytical one would be a strong hint as to whether ODENet can be applied to more complicated systems. Additionally, systems with known derivative provide the luxury of dataset synthesis.

As suggested in \cite{Bengio2012}, the first step in debugging a machine learning system is to reduce the training set so that the model easily overfits. For the phaser, this could be done with pink noise data thanks to its amplitude spectrum that makes phaser's impact instantly audible and visible on a spectrogram (as in \Figure{fig:pink_noise_phasered}). If ODENet cannot fit that data and there is no bug in the implementation, then there is little chance that it could be successfully used for phaser modeling. If it can, then more \ac{MLP} configurations with different regularization and learning rate schedules could be explored to find the one that is capable of learning the derivative of the phaser system.

If the state vector describing a dynamical system has more than one entry and these entries are measurable, we could provide even more guidance to the derivative network during training. Measurable states are the voltage across the capacitors in case of analog models, as described in \cite{Parker2019}, or the content of buffers in case of digital models. Again, if the network is not able to learn the derivative on such enriched dataset (which comes down to learning additions and multiplications), there is no possibility it could learn from pure audio data.

In this work, the learned \ac{ODE} was always in the time domain. There are, however, many more possible feature spaces, some of them transform-based, others provided by specialized \acp{ANN}. %TODO: Cite Amiriparian
The space in which the system-governing \ac{ODE} exists could also possibly be learned from data. This latent space is called a manifold \cite{Goodfellow-et-al-2016} or an emergent space. % TODO: Cite Kemeth

Should the attempts of learning a network the derivative of a phaser succeed, a similar analysis to what has been done for the diode clipper should follow, i.e., network size reduction, solver comparison, aliasing examination, etc. Moreover, different audio effects could be considered for modeling. A performance analysis or measurement could determine the potential benefits of industrial applications of ODENet in \ac{VA} modeling.

Finally, the ultimate goal of \ac{VA} models is a real-time implementation in a \ac{DAW} plugin. Implementing a plugin using ODENet and measuring its performance would help in finding out whether ODENet can be successfully applied in a music production or performance environment.
